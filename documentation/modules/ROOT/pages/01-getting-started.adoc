= Getting Started with OpenShift Streams for Apache Kafka

As a developer of applications and services, you can use OpenShift Streams for Apache Kafka to create and set up Kafka instances and connect your applications and services to these instances. Streams for Apache Kafka is a managed cloud service that enables you to add Kafka data-streaming functionality in your applications without having to install, configure, run, and maintain your own Kafka clusters.

[#redhataccount]
== Create a Red Hat account

You need a Red Hat account to provision a managed Kafka instance. If you don’t have a Red Hat account, this is how you can create one: 

. Go to https://console.redhat.com[console.redhat.com]. 

. Click the *Register for a Red Hat account* link to create a Red Hat account.
+
image::register-redhat-account.png[width=60%]
+
Be sure to select a *Personal account* type.

[#kafka]
== Provision a Kafka instance in OpenShift Streams for Apache Kafka

. Go to https://console.redhat.com[console.redhat.com] and log in with your Red Hat account.

. On the https://console.redhat.com[console.redhat.com] landing page, select *Application and Data Services* from the menu on the left.

. On the Application and Data Services landing page, select *Streams for Apache Kafka → Kafka Instances*.
+
image::rhosak-kafka-instances.png[]

. On the Kafka Instances overview page, click the *Create Kafka* instance button. Enter a unique name and select the relevant _Cloud region_ for your Kafka instance and click *Create instance*. This starts the provisioning process for your Kafka instance. 

. The new Kafka instance is listed in the instances table. After a couple of minutes, your instance should be marked as ready. 
+
image::rhosak-kafka-instance-ready.png[]

. When the instance _Status_ is `Ready`, you can start using the Kafka instance. You can use the options icon (three vertical dots) to view, connect to, or delete the instance as needed.

[NOTE]
====
Although you can see Kafka instances created by other users in your organization, you can't manage those instances. Only the user who creates an instance can edit or delete the instance, setup permissions and create or delete topics.
====

[#serviceaccount]
== Create a Service Account to connect to a Kafka instance

To connect your applications or services to a Streams for Apache Kafka instance, you need to create a service account.

. On the *Kafka Instances* overview page, select the *Options* icon (the three dots) for the Kafka instance you just created. Select *View connection information*.

. Copy the *Bootstrap server* endpoint to a secure location. You will need this when connecting to your Kafka instance.

. Click *Create service account* to set up the service account. Enter a unique service account name and an optional description, and click *Create*.

. Copy the generated *Client ID* and *Client Secret* to a secure location. These are the credentials that you’ll use to connect to this Kafka instance.
+
[IMPORTANT]
====
The generated credentials are displayed only one time, so ensure that you’ve successfully and securely saved the copied credentials before closing the credentials window. 
====

. After saving the generated credentials, select the confirmation check box and close the Credentials window.
+
image::rhosak-service-account.png[]

You’ll use the service account information that you saved to configure your application to connect to your Kafka instances when you’re ready. For example, if you plan to use link:https://github.com/edenhill/kcat[kcat] to interact with your Kafka instance, you’ll use this information to set your bootstrap server and client environment variables.

[#serviceaccountpermissions]
== Set Permissions for a Service Account

After you create a service account to connect to a Kafka instance, you must also set the appropriate level of access for that new account in the Access Control List (ACL) of the Kafka instance. Streams for Apache Kafka uses ACLs provided by Kafka that enable you to manage how other user accounts and service accounts are permitted to interact with the Kafka resources that you create.

[NOTE]
====
For this workshop, you will set permissions for all accounts at once. The reason behind this is that the Service Binding functionality we are going to use later in the workshop to bind applications to the Kafka instance will create a new service account. By using wildcard permissions, you ensure that this service account has the required permissions to connect to the Kafka instance. 
====

. On the *Kafka Instances* page, click the name of the Kafka instance you previously created.

. Click the *Access* tab to view the current ACL for this instance.
+
image::rhosak-default-access.png[]

. Click *Manage access*, use the *Account* drop-down menu to select to select *All accounts*, and click *Next*.

. Select the *Consume from a topic* and *Produce to a topic* from the *Task-based permission* possibilities. Set the topic and consumer group names to `is` and `*`.
+
These permissions enable applications associated with any service account to create topics in the instance, to produce and consume messages in any topic in the instance, and to use any consumer group.
+
.Example ACL permissions for all accounts
[cols="25%,25%,25%,25%"]
|===
h|Resource type
h|Resource identifier and value
h|Access type
h|Operation

|`Topic`
|`Is` = `*`
|`Allow`
|`Read`,`Write`,`Create`,`Describe`

|`Consumer group`
|`Is` = `*`
|`Allow`
|`Read`
|===
+
Click *Save*.
+
image::rhosak-access-serviceaccount.png[]

[#topic]
== Create a Kafka Topic in OpenShift Streams for Apache Kafka

After you create a Kafka instance, you can create Kafka topics to start producing and consuming messages in your services.

. In the *Kafka Instances* page of the web console, click the name of the Kafka instance that you want to add a topic to.

. Select the *Topics* tab, click *Create topic*, and follow the guided steps to define the topic details. Click *Next* to complete each step and click *Finish* to complete the setup.
+
image:rhosak-create-topic.png[]
+
* *Topic name*: Enter a unique topic name, such as `my-first-kafka-topic`.
* *Partitions*: Set the number of partitions for this topic. This example sets the partition to 1 for a single partition. Partitions are distinct lists of messages within a topic and enable parts of a topic to be distributed over multiple brokers in the cluster. A topic can contain one or more partitions, enabling producer and consumer loads to be scaled.
+
NOTE: You can increase the number of partitions later, but you cannot decrease them.
* *Message retention*: Set the message retention time and size to the relevant value and increment. The default retention time is set to `A week` and the retention size to `Unlimited`. Message retention time is the amount of time that messages are retained in a topic before they are deleted or compacted, depending on the cleanup policy. Retention size is the maximum total size of all log segments in a partition before they are deleted or compacted.
* *Replicas*: For this release of Streams for Apache Kafka, the replicas are preconfigured. On a trial Kafka instance, whichg only consists of one broker, the number of partition replicas for the topic and the minimum number of follower replicas that must be in sync with a partition leader are set to `1`. Replicas are copies of partitions in a topic. Partition replicas are distributed over multiple brokers in the cluster to ensure topic availability if a broker fails. When a follower replica is in sync with a partition leader, the follower replica can become the new partition leader if needed.

After you complete the topic setup, the new Kafka topic is listed in the topics table. You can now start producing and consuming messages to and from this topic using services that you connect to this instance.